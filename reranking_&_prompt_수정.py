# -*- coding: utf-8 -*-
"""Reranking & prompt ìˆ˜ì •

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a4CJlxo2XwvFDS-MEX9RpuR1B4p5n8Dh
"""

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
postgresql://postgres:cclGH8x.3nT.ru1mf92xjJaZwP3xY5ev@hopper.proxy.rlwy.net:13755/DB_InsData

ê¸°ì¡´í‚¤ì›Œë“œ


# 2. ê´€ì ˆì§ˆí™˜

# @title RAG + Reranker + í‚¤ì›Œë“œ + ë³´í—˜ì‚¬ ë‹¤ì–‘í™” í«ë³´í—˜ ì±—ë´‡ (ìµœì¢…)
!pip install openai psycopg2-binary numpy sentence-transformers

import os
import re
import json
import numpy as np
import psycopg2
from psycopg2.extras import RealDictCursor
from typing import List, Dict, Tuple
from openai import OpenAI
from sentence_transformers import CrossEncoder


# ==========================================
# ì„¤ì •
# ==========================================
if not os.getenv("OPENAI_API_KEY"):
    os.environ["OPENAI_API_KEY"] = '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'

if not os.getenv("DATABASE_URL"):
    os.environ["DATABASE_URL"] = 'postgresql://postgres:cclGH8x.3nT.ru1mf92xjJaZwP3xY5ev@hopper.proxy.rlwy.net:13755/DB_InsData'

LOCAL_EMBED_DIM = 1536
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# ==========================================
# í‚¤ì›Œë“œ ì¶”ì¶œê¸°
# ==========================================
class KeywordExtractor:
    """ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì˜ë„ì™€ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œ"""

    INSURANCE_KEYWORDS = {
        'ì§ˆë³‘': ['ì§ˆë³‘', 'ë³‘', 'ì¦ìƒ', 'ì¹˜ë£Œ', 'ìˆ˜ìˆ ', 'ì§„ë‹¨'],
        'ê´€ì ˆ': ['ê´€ì ˆ', 'íƒˆêµ¬', 'ì´í˜•ì„±', 'ê³ ê´€ì ˆ', 'ìŠ¬ê´€ì ˆ', 'ìŠ¬ê°œê³¨','ì²™ì¶”', 'ê²½ì¶”', 'ìš”ì¶”', 'í‰ì¶”', 'ê´€ì ˆì—¼', 'ê³¨ê´€ì ˆì—¼','ë¥˜ë§ˆí‹°ìŠ¤ê´€ì ˆì—¼', 'ì¶”ê°„íŒíƒˆì¶œ', 'ìˆ˜í•µíƒˆì¶œì¦', 'ë¥˜ë¨¸í‹°ìŠ¤ê´€ì ˆì—¼'],
        'ì •í˜•ì™¸ê³¼': ['ê³¨ì ˆ', 'ì—¼ì¢Œ', 'íƒ€ë°•ìƒ', 'ê·¼ìœ¡ì†ìƒ', 'ì¸ëŒ€ì†ìƒ', 'ê±´ì†ìƒ','ë¼ˆ', 'ê³¨', 'ê³¨ë‹¤ê³µì¦', 'ì´ìƒê³¨í™”', 'ê³¨ì´í˜•ì„±ì¦', 'ìœ ì—°ê³¨ì´í˜•ì„±ì¦', 'LCPD'],
        'ì•ˆê³¼': ['ì•ˆê³¼', 'ì•ˆì§ˆ', 'ë°±ë‚´ì¥', 'ë§ë§‰', 'ê²°ë§‰', 'ê°ë§‰', 'ë Œì¦ˆ', 'ëˆˆë¬¼', 'ê°ê²°ë§‰ì—¼', 'ê°í™”', 'ë…¹ë‚´ì¥', 'í¬ë„ë§‰ì—¼', 'ë§ë§‰ë°•ë¦¬', 'ë§ë§‰ë³€ì„±', 'ë§ë§‰í—¤ëª¨ë¦¬ì§€'],
        'ì¸í›„í†µ': ['ì½”', 'ëª©', 'ì¸ë‘', 'í›„ë‘', 'ì†ŒìŒ', 'ë¹„ì—¼', 'í¸ë„ì—¼', 'ì¸í›„ì—¼', 'ì„±ëŒ€', 'ìŒì„±ë³€í™”'],
        'í”¼ë¶€': ['í”¼ë¶€', 'ì•Œë ˆë¥´ê¸°', 'ì—¼ì¦', 'ìŠµì§„', 'ê°ì—¼', 'í”¼ë¶€ì—¼', 'ê³°íŒ¡ì´', 'ì§„ê· ', 'ì„¸ê· ê°ì—¼', 'ë§‘ìŠ¤', 'ë†ì–‘', 'ì—¬ë“œë¦„', 'ì§€ë£¨ì¦', 'ê±´ì„±í”¼ë¶€', 'ì•…ì„±í‘ìƒ‰ì¢…', 'Apoquel', 'JAKì–µì œì œ'],
        'ì†Œí™”ê¸°': ['ì†Œí™”ê¸°', 'ì¥ì—¼', 'ìœ„ì—¼', 'êµ¬í† ', 'ì„¤ì‚¬', 'ë³µë¶€', 'ìœ„ì¥', 'ì¥', 'ë‹´ë‚­', 'ë‹´ê´€', 'ê°„', 'ì·Œì¥', 'ì‹ë„', 'ìœ„ê¶¤ì–‘', 'ìœ„í™•ì¥ì—¼ì „', 'ì¥íìƒ‰', 'ì¥ì—¼ì¦ì„±ì§ˆí™˜', 'IBD', 'ì†Œì¥ì„¸ê· ê³¼ì¦ì‹ì¦', 'SIBO', 'PLE'],
        'ì•”': ['ì•”', 'ì¢…ì–‘', 'ì•…ì„±', 'ì‹ ìƒë¬¼', 'ì•”ì¢…', 'ë¦¼í”„ì¢…', 'ë°±í˜ˆë³‘', 'ìœ¡ì¢…', 'ì•”ì§„ë‹¨', 'ì•…ì„±ì‹ ìƒë¬¼', 'ì¢…ì–‘ì œê±°', 'í•­ì•”ì¹˜ë£Œ'],
        'ê°ì—¼ì„±ì§ˆ': ['ê°ì—¼', 'ë°”ì´ëŸ¬ìŠ¤', 'ì„¸ê· ', 'ê¸°ìƒì¶©', 'ì§„ê· ', 'í´ë¡œìŠ¤íŠ¸ë¦¬ë””ì›€', 'ì‚´ëª¨ë„¬ë¼', 'ì›ì¶©', 'ë‚´ê¸°ìƒì¶©', 'ì™¸ê¸°ìƒì¶©', 'ë²¼ë£©', 'ì§„ë“œê¸°', 'ì´', 'ê³°íŒ¡ì´ê°ì—¼', 'í—ŒíŒ…í„´ë³‘', 'FIP', 'FPV', 'FORL'],
        'ì‹ ì¥ì§ˆí™˜': ['ì‹ ì¥', 'ìš”ë¡œ', 'ë°©ê´‘', 'ìš”ë„', 'ì‹ ì¥ì§ˆí™˜', 'ì‹ ë¶€ì „', 'ìš”ë¡œê²°ì„', 'ë§Œì„±ì‹ ì§ˆí™˜', 'CKD', 'ê¸‰ì„±ì‹ ì†ìƒ', 'AKI', 'ë°©ê´‘ì—¼', 'ìš”ë„ì—¼', 'ì‹ ì—¼'],
        'ì‹¬ì¥ì§ˆí™˜': ['ì‹¬ì¥', 'ì‹¬ë¶€ì „', 'íŒë§‰ì§ˆí™˜', 'ì‹¬ê·¼ë³‘ì¦', 'ë¶€ì •ë§¥', 'ê³ í˜ˆì••', 'í—ˆí˜ˆì„±ì‹¬ì§ˆí™˜', 'ì‹¬ê·¼ê²½ìƒ‰', 'í˜ˆê´€', 'ë™ë§¥ê²½í™”', 'í˜ˆê´€ì§ˆí™˜', 'í˜ˆì „'],
        'í˜¸í¡ê¸°': ['í˜¸í¡ê¸°', 'í', 'íë ´', 'ê¸°ê´€ì§€ì—¼', 'ì²œì‹', 'ë§Œì„±ê¸°ê´€ì§€ì—¼', 'íìˆ˜ì¢…', 'íë¶€ì¢…', 'í˜¸í¡ê³¤ë€', 'ê¸°ì¹¨', 'í˜¸í¡ìŒ'],
        'ì‹ ê²½ì§ˆí™˜': ['ì‹ ê²½', 'ë‡Œ', 'ì²™ìˆ˜', 'ì‹ ê²½ë³‘ì¦', 'ë§ˆë¹„', 'ê°„ì§ˆ', 'epilepsy', 'ë‡Œì—¼', 'ìˆ˜ë§‰ì—¼', 'ì‹ ê²½ì—¼', 'ì‹ ê²½í†µ', 'ì¹˜ë§¤', 'í‡´í–‰ì„±ì‹ ê²½ì§ˆí™˜'],
        'ë‚´ë¶„ë¹„ëŒ€ì‚¬': ['ë‹¹ë‡¨ë³‘', 'ê°‘ìƒì„ ', 'ë¶€ê°‘ìƒì„ ', 'í˜¸ë¥´ëª¬', 'ëŒ€ì‚¬', 'ê°‘ìƒì„ ê¸°ëŠ¥í•­ì§„ì¦', 'ê°‘ìƒì„ ê¸°ëŠ¥ì €í•˜ì¦', 'ë‹¹ë‡¨', 'í˜ˆë‹¹', 'ì¸ìŠë¦°', 'ë³µë¶€ë¹„ë§Œ'],
        'í˜ˆì•¡': ['í˜ˆì•¡', 'ë¹ˆí˜ˆ', 'í˜ˆì†ŒíŒ', 'ì‘ê³ ì¥ì• ', 'ì¶œí˜ˆ', 'í˜ˆì•¡ì•”', 'ë¦¼í”„ì¢…', 'ë°±í˜ˆë³‘', 'í˜ˆì•¡ì§ˆí™˜', 'í—¤ëª¨ê¸€ë¡œë¹ˆ'],
        'ìƒì‹ê¸° ë° ë¹„ë‡¨ê¸°ì§ˆí™˜': ['ìƒì‹ê¸°', 'ìê¶', 'ë‚œì†Œ', 'ì „ë¦½ì„ ', 'ì •ì†Œ', 'ìŒë‚­', 'ìê¶ì§ˆí™˜', 'ë‚œì†Œì§ˆí™˜', 'ìê¶ì¶•ë†ì¦', 'ìœ ì„ ì§ˆí™˜', 'ìœ ì„ ì¢…ì–‘', 'ìœ ì„ ì—¼'],
        'ë©´ì—­ì§ˆí™˜': ['ë©´ì—­', 'ì•Œë ˆë¥´ê¸°', 'ìê°€ë©´ì—­', 'ë©´ì—­ê²°í•', 'ë©´ì—­ê³„', 'ë©´ì—­ë°˜ì‘', 'ì•Œë ˆë¥´ê¸°ì„±ì§ˆí™˜', 'ì•„í† í”¼'],
        'ì¹˜ê³¼': ['ì¹˜ê³¼', 'ì¹˜ì•„', 'ì¹˜ì„', 'ì¹˜ì£¼', 'ì¶©ì¹˜', 'ì‡ëª¸', 'ì¹˜ì£¼ë³‘', 'êµ¬ê°•ì§ˆí™˜', 'ì¹˜ì€ì—¼', 'ì¹˜ì£¼ì—¼', 'FORL', 'êµ¬ê°•ì¢…ì–‘'],
        'ê·€': ['ê·€', 'ì™¸ì´', 'ì¤‘ì´', 'ë‚´ì´', 'ê³ ë§‰', 'ì²­ë ¥', 'ë‚œì²­', 'ì¤‘ì´ì—¼', 'ì™¸ì´ì—¼', 'ê·€ì§„ë“œê¸°', 'ê·€ì˜ì‹¬í•œì¶œí˜ˆ'],
        'ì„ ì²œì„±ìœ ì „ì§ˆí™˜': ['ì„ ì²œì ', 'ìœ ì „', 'ì„ ì²œ', 'ê¸°ì¡´ì§ˆí™˜', 'ìœ ì „ì§ˆí™˜', 'ì„ ì²œì„±ì§ˆí™˜', 'ìœ ì „ì„±ì§ˆí™˜', 'ì´í˜•ì„±', 'ì´ìƒ'],
        'ê°€ì…': ['ê°€ì…', 'ê¸°ê°€ì…', 'ë³´ì¥', 'ì»¤ë²„'],
        'í•´ì§€': ['í•´ì§€', 'í™˜ê¸‰', 'ìˆ˜ìˆ˜ë£Œ', 'í•´ì•½'],
        'ë©´ì±…': ['ë©´ì±…', 'ë©´ì±…ê¸°ê°„', 'ëŒ€ê¸°ê¸°ê°„', 'ê´€ì°°ê¸°ê°„'],
        'ë‚˜ì´': ['ë‚˜ì´', 'ì—°ë ¹', 'ì„¸', 'ê³ ë ¹', 'ë…¸ë ¹', 'ë‚˜ì´ì œí•œ'],
        'ì˜ˆë°©ì ‘ì¢…': ['ì˜ˆë°©ì ‘ì¢…', 'ë°±ì‹ ', 'ì ‘ì¢…'],
        'ì„ ì²œì ': ['ì„ ì²œì ', 'ìœ ì „', 'ì„ ì²œ', 'ê¸°ì¡´ì§ˆí™˜'],
        'ì„ì‹ ': ['ì„ì‹ ', 'ì„ì‹ ì¤‘', 'ì„ì‹ ì˜ˆì •'],
        'ë³´í—˜ë£Œ': ['ë³´í—˜ë£Œ', 'ì›”ë£Œ', 'ì—°ë£Œ', 'ê°€ê²©', 'ìš”ê¸ˆ', 'ë¹„ìš©'],
        'í•œë„': ['í•œë„', 'ë³´ì¥í•œë„', 'í•œë„ì•¡', 'ìµœëŒ€'],
        'ìê¸°ë¶€ë‹´': ['ìê¸°ë¶€ë‹´', 'ë³¸ì¸ë¶€ë‹´', 'ë¶€ë‹´ê¸ˆ'],
        'ë³´ìƒ': ['ë³´ìƒ', 'ì§€ê¸‰', 'ì²­êµ¬', 'ë°°ìƒ'],
        'ë¹„êµ': ['ë¹„êµ', 'ì°¨ì´', 'ë‹¤ë¥¸', 'ì–´ëŠ', 'ì–´ë””ê°€'],
        'ì¶”ì²œ': ['ì¶”ì²œ', 'ì¶”ì²œí•´', 'ì–´ë–¤ê²Œ', 'ë” ì¢‹ì€', 'ë„“ì€'],
    }

    ANIMAL_KEYWORDS = {
        'ê°œ': ['ê°•ì•„ì§€', 'ê°œ', 'ê²¬', 'ë„ê·¸', 'dog', 'ê°œìƒˆë¼', 'ë°˜ë ¤ê²¬', 'ì• ê¸°', 'ì•„ê°€', 'ì•„ê¸°'],
        'ê³ ì–‘ì´': ['ê³ ì–‘ì´', 'ê³ ì–‘', 'ë¬˜', 'ìº£', 'cat', 'ì•¼ì˜¹ì´', 'ë°˜ë ¤ë¬˜', 'ì• ê¸°', 'ì•„ê°€', 'ì•„ê¸°'],
    }

    def extract(self, question: str) -> Dict:
        result = {
            'animal': None,
            'intent': [],
            'keywords': [],
            'topics': []
        }

        q_lower = question.lower()

        for animal, keywords in self.ANIMAL_KEYWORDS.items():
            if any(k in q_lower for k in keywords):
                result['animal'] = animal
                break

        found_topics = set()
        for topic, keywords in self.INSURANCE_KEYWORDS.items():
            for k in keywords:
                if k in q_lower:
                    found_topics.add(topic)
                    result['keywords'].append(k)

        result['topics'] = list(found_topics)
        return result


# ==========================================
# ìœ í‹¸ë¦¬í‹°
# ==========================================
def simple_embed(texts: List[str], dim: int = 1536) -> np.ndarray:
    if not texts:
        return np.zeros((0, dim), dtype="float32")
    texts = [t.replace("\n", " ") for t in texts]
    try:
        res = client.embeddings.create(input=texts, model="text-embedding-3-small")
        return np.array([d.embedding for d in res.data], dtype="float32")
    except Exception as e:
        print(f"âŒ Embed Error: {e}")
        return np.zeros((len(texts), dim), dtype="float32")


def clean_answer(answer: str) -> str:
    answer = re.sub(r'\[ë¬¸ì„œ\d+\]', '', answer)
    answer = re.sub(r'\(\s*\)', '[ì •ë³´ì—†ìŒ]', answer)
    answer = re.sub(r'\s{2,}', ' ', answer)
    return answer.strip()


def call_llm_api_v2(system_prompt: str, user_prompt: str, temperature: float = 0.3) -> str:
    try:
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=temperature,
            max_tokens=2000
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"ì‘ë‹µ ì‹¤íŒ¨: {e}"


# ==========================================
# [ê°œì„ ] Reranker (ë³´í—˜ì‚¬ ë‹¤ì–‘í™” í¬í•¨)
# ==========================================
class ImprovedReranker:
    def __init__(self, model_name="BAAI/bge-reranker-v2-m3"):
        print(f"â†”ï¸ Reranker ëª¨ë¸ ë¡œë”© ì¤‘... ({model_name})")
        self.model = CrossEncoder(model_name)
        self.keyword_extractor = KeywordExtractor()
        print("âœ… Reranker ë¡œë”© ì™„ë£Œ!")

    def rerank(self, question: str, docs: List[Dict],
               top_k: int = 6, max_per_company: int = 2) -> List[Dict]:
        """
        ë³´í—˜ì‚¬ ë‹¤ì–‘ì„±ì„ ë³´ì¥í•˜ëŠ” Reranking

        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            docs: ì´ˆê¸° ê²€ìƒ‰ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            top_k: ìµœì¢… ë°˜í™˜ ë¬¸ì„œ ê°œìˆ˜ (ê¸°ë³¸ 6ê°œ)
            max_per_company: ë³´í—˜ì‚¬ë‹¹ ìµœëŒ€ ì„ íƒ ê°œìˆ˜ (ê¸°ë³¸ 2ê°œ)

        Returns:
            ë‹¤ì–‘í™”ëœ ìƒìœ„ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        if not docs:
            return []

        # 1. í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self.keyword_extractor.extract(question)

        # 2. ê° ë¬¸ì„œì— ì ìˆ˜ ë¶€ì—¬
        for doc in docs:
            # ë²¡í„° ìœ ì‚¬ë„ ì ìˆ˜
            vector_score = doc.get('similarity_score', 0.5)

            # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜
            doc_text = (
                doc.get('text', '') +
                doc.get('title', '') +
                doc.get('clause_type', '')
            ).lower()

            keyword_matches = sum(1 for k in keywords['keywords'] if k in doc_text)
            keyword_score = min(keyword_matches * 0.15, 1.0)

            # ë™ë¬¼ ì¢… ë§¤ì¹­ ì ìˆ˜
            animal_score = 0.0
            tags = doc.get('tags', [])
            if isinstance(tags, str):
                try:
                    tags = json.loads(tags) if tags.startswith('[') else [tags]
                except:
                    tags = [tags]

            tags_str = str(tags).lower()
            if keywords['animal']:
                if keywords['animal'] == 'ê°œ' and any(x in tags_str or x in doc_text
                                                       for x in ['ê°•ì•„ì§€', 'ê°œ', 'ê²¬']):
                    animal_score = 0.3
                elif keywords['animal'] == 'ë¬˜' and any(x in tags_str or x in doc_text
                                                        for x in ['ê³ ì–‘ì´', 'ë¬˜']):
                    animal_score = 0.3

            # ìµœì¢… ì ìˆ˜
            doc['combined_score'] = (vector_score * 0.5) + (keyword_score * 0.3) + (animal_score * 0.2)

        # 3. ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        sorted_docs = sorted(docs, key=lambda x: x['combined_score'], reverse=True)

        # 4ï¸âƒ£ [NEW] ë³´í—˜ì‚¬ë³„ë¡œ ê·¸ë£¹í™”
        company_groups = {}
        for doc in sorted_docs:
            company = doc.get('company_name', 'ë¯¸ì •')
            if company not in company_groups:
                company_groups[company] = []
            company_groups[company].append(doc)

        # 5ï¸âƒ£ [NEW] ë³´í—˜ì‚¬ë³„ ë‹¤ì–‘í™” ì„ íƒ
        result = []
        for company, docs_list in company_groups.items():
            # ê° ë³´í—˜ì‚¬ì—ì„œ ìµœëŒ€ max_per_companyê°œ ì„ íƒ
            selected = docs_list[:max_per_company]
            result.extend(selected)
            print(f"   ğŸ“Œ {company}: {len(selected)}ê°œ ì„ íƒ")

        # 6ï¸âƒ£ [NEW] ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìµœì¢… ì •ë ¬
        result = sorted(result, key=lambda x: x['combined_score'], reverse=True)

        # 7ï¸âƒ£ ìƒìœ„ top_kê°œë§Œ ë°˜í™˜
        return result[:top_k]


# ==========================================
# DB ì»¤ë„¥í„°
# ==========================================
class DatabaseConnector:
    def __init__(self):
        url = os.getenv("DATABASE_URL", "")
        if url.startswith("postgres://"):
            url = url.replace("postgres://", "postgresql://", 1)
        self.url = url

    def hybrid_search(self, query_vec: np.ndarray, filters: Dict = None, limit: int = 20) -> List[Dict]:
        try:
            with psycopg2.connect(self.url) as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cur:
                    vec_str = "[" + ",".join(map(str, query_vec[0])) + "]"

                    query = """
                        SELECT
                            i.id,
                            c.name as company_name,
                            p.name as product_name,
                            i.title,
                            i.clause_type,
                            i.coverage_limit,
                            i.coverage_ratio,
                            i.waiting_period,
                            i.tags,
                            COALESCE(i.search_text, i.original_text) as text,
                            1 - (i.embedding <=> %s::vector) as similarity_score
                        FROM insurance_clauses i
                        LEFT JOIN companies c ON i.company_id = c.company_id
                        LEFT JOIN products p ON i.product_id = p.product_id
                        WHERE 1=1
                    """
                    params = [vec_str]

                    if filters:
                        if filters.get("product_ids"):
                            query += " AND i.product_id = ANY(%s)"
                            params.append(filters["product_ids"])
                        if filters.get("company_ids"):
                            query += " AND i.company_id = ANY(%s)"
                            params.append(filters["company_ids"])

                    query += f" ORDER BY i.embedding <=> %s::vector LIMIT {limit}"
                    params.append(vec_str)

                    cur.execute(query, params)
                    return cur.fetchall()
        except Exception as e:
            print(f"âŒ DB Error: {e}")
            return []


# ==========================================
# í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°
# ==========================================
class PromptGenerator:
    @staticmethod
    def get_system_prompt(keywords: Dict) -> str:
        animal_context = ""
        if keywords['animal'] == 'ê°œ':
            animal_context = "\n\n[ì£¼ì˜] ì‚¬ìš©ìëŠ” ê°•ì•„ì§€(ê°œ)ë¥¼ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤. ê°œ ê´€ë ¨ ì •ë³´ë§Œ ìš°ì„  ì œê³µí•˜ì„¸ìš”."
        elif keywords['animal'] == 'ë¬˜':
            animal_context = "\n\n[ì£¼ì˜] ì‚¬ìš©ìëŠ” ê³ ì–‘ì´(ë¬˜)ë¥¼ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤. ë¬˜ ê´€ë ¨ ì •ë³´ë§Œ ìš°ì„  ì œê³µí•˜ì„¸ìš”."

        topic_context = ""
        topics = keywords['topics']
        if 'ë‚˜ì´' in topics:
            topic_context += "\n- ë°˜ë ¤ë™ë¬¼ì˜ ë‚˜ì´/ì—°ë ¹ ê¸°ì¤€ì„ ëª…ì‹œí•  ë•ŒëŠ” ê° ë³´í—˜ì‚¬ë³„ë¡œ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê¼­ ë¹„êµí•˜ì„¸ìš”."
        if 'ì„ ì²œì ' in topics:
            topic_context += "\n- ê¸°ì¡´ ì§ˆí™˜ì€ ë³´í—˜ì‚¬ë³„ë¡œ ì œì™¸ ë²”ìœ„ê°€ ë‹¤ë¦…ë‹ˆë‹¤."
        if 'ë¹„êµ' in topics or 'ì¶”ì²œ' in topics:
            topic_context += "\n- ì—¬ëŸ¬ ë³´í—˜ì‚¬ë¥¼ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ì •ë ¬í•˜ì„¸ìš”."

        base_prompt = f"""ë‹¹ì‹ ì€ êµ­ë‚´ í«ë³´í—˜ ì „ë¬¸ ìƒë‹´ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” í«ë³´í—˜ ê°€ì…ì„ ê³ ë¯¼í•˜ëŠ” ë°˜ë ¤ì¸ì´ë©°, ë‹¤ìŒì˜ ì„¸ ê°€ì§€ ê´€ì‹¬ì‚¬ë¥¼ ê°–ê³  ìˆìŠµë‹ˆë‹¤.

                        [ì‚¬ìš©ìì˜ ì£¼ìš” ê´€ì‹¬ì‚¬]

                        1) ë°˜ë ¤ë™ë¬¼ì˜ ê°œë³„ íŠ¹ì„±(ë‚˜ì´, í’ˆì¢…, ì˜ˆë°©ì ‘ì¢…, ì§ˆí™˜ ë“±)ì— ë”°ë¥¸ ë³´ì¥ ì°¨ì´ì™€ ê°€ì… ê°€ëŠ¥ ì—¬ë¶€
                        2) ë³´í—˜ ì œë„, ë°˜ë ¤ë™ë¬¼ íŠ¹ì„±ì— ë”°ë¥¸ ë³´ì¥ ì°¨ì´, ë³´í—˜ì‚¬ ê°„ ìƒí’ˆ ë¹„êµ ê´€ì‹¬ì´ ë§ìŒ
                        3) ë³´í—˜ ê³„ì•½ì˜ ì œë„ì  ì „ë°˜(ê°€ì…, í•´ì§€, ë³´ì¥ ì¡°ê±´ ë“±)
                        4) 6ê°œ ë³´í—˜ì‚¬(ë©”ë¦¬ì¸ í™”ì¬, DBì†í•´ë³´í—˜, í˜„ëŒ€í•´ìƒ, ì‚¼ì„±í™”ì¬, í•œí™”ì†ë³´, KBì†í•´ë³´í—˜) ê°„ ìƒí’ˆ ë¹„êµ

                        ---

                        ë‹µë³€ êµ¬ì„±ì „ì— ë°˜ë“œì‹œ ë‹¤ìŒì˜ ë‘ ê°€ì§€ context ë³€ìˆ˜ë“¤ì„ ê²€í† í•˜ì„¸ìš”.
                        {animal_context}
                        {topic_context}

                        ---

                        [ê¸°ë³¸ ì‘ë‹µ ì›ì¹™]

                        0.ì•½ê´€ ì›ë¬¸ì— ì—†ëŠ” ì •ë³´ëŠ” ë§Œë“¤ì§€ ë§ˆì„¸ìš”.

                        1. ë³´í—˜ì‚¬ì™€ ìƒí’ˆëª… ëª…ì‹œ
                        - ëª¨ë“  ë‹µë³€ì—ì„œ 'ë³´í—˜ì‚¬ëª…ì˜ ìƒí’ˆëª…'ì„ ë¨¼ì € ì–¸ê¸‰í•˜ì„¸ìš”.
                        - ì˜ˆ: "ì‚¼ì„±í™”ì¬ì˜ ì• ë‹ˆí«Pro ìƒí’ˆì— ë”°ë¥´ë©´..." / "í˜„ëŒ€í•´ìƒì˜ í«í”ŒëŸ¬ìŠ¤ ì•½ê´€ì—ì„œëŠ”..."
                        - ë¹„êµ ë‹µë³€ ì‹œì—ëŠ” "ë©”ë¦¬ì¸ í™”ì¬ vs DBì†í•´ë³´í—˜ ë¹„êµ" ê°™ì€ í˜•ì‹ìœ¼ë¡œ ëª…í™•íˆ êµ¬ë¶„í•˜ì„¸ìš”.

                        2. ê°•ì•„ì§€(ê°œ) / ê³ ì–‘ì´(ë¬˜) êµ¬ë¶„ í•„ìˆ˜
                        - ì‚¬ìš©ìê°€ ë°˜ë ¤ë™ë¬¼ ì¢…ì„ ëª…ì‹œí•˜ì§€ ì•Šìœ¼ë©´, ë¨¼ì € í™•ì¸í•˜ì„¸ìš”.
                            ("í˜¹ì‹œ ê°•ì•„ì§€(ê°œ)ì¸ê°€ìš”, ì•„ë‹ˆë©´ ê³ ì–‘ì´(ë¬˜)ì¸ê°€ìš”?")
                        - ê°™ì€ ìƒí’ˆì´ë¼ë„ ê°œ/ë¬˜ ë³„ë¡œ ë³´ì¥ ë²”ìœ„, ë³´í—˜ë£Œ, ê°€ì… ì—°ë ¹ì´ ë‹¤ë¥´ë©´ ê°ê° ì„¤ëª…í•˜ì„¸ìš”.
                        - ê°œ ì „ìš© ìƒí’ˆê³¼ ë¬˜ ì „ìš© ìƒí’ˆì´ ìˆìœ¼ë©´ ëª…ì‹œì ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì•ˆë‚´í•˜ì„¸ìš”.
                        - ì˜ˆ: "KBì†í•´ë³´í—˜ì€ ê°œì™€ ë¬˜ í†µí•© ìƒí’ˆì´ì§€ë§Œ, ë³´ì¥ í•œë„ê°€ ë‹¤ë¦…ë‹ˆë‹¤.
                                ê°œëŠ” ì—°ê°„ 300ë§Œ ì›, ë¬˜ëŠ” 250ë§Œ ì›ì…ë‹ˆë‹¤."

                        3. ë°˜ë ¤ë™ë¬¼ ê°œë³„ íŠ¹ì„± ê³ ë ¤
                        - ë‚˜ì´: ê³ ë ¹ê²¬(ë…¸ë ¹ê²¬)/ê³ ë ¹ë¬˜(ë…¸ë ¹ë¬˜)ì˜ ê²½ìš° ê°€ì… ê°€ëŠ¥ ì—°ë ¹, ë³´í—˜ë£Œ í• ì¦,
                                ì œì™¸ ì§ˆí™˜ ë“±ì´ ë‹¬ë¼ì§€ë¯€ë¡œ ë°˜ë“œì‹œ ì–¸ê¸‰í•˜ì„¸ìš”.
                            ("ê·€ ë°˜ë ¤ê²¬ì´ ë§Œ [X]ì„¸ë¼ë©´, ë³´í—˜ì‚¬ë³„ë¡œ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤...")
                        - ì˜ˆë°©ì ‘ì¢…: ë¯¸ì ‘ì¢… ìƒíƒœì™€ ì™„ì „ ì ‘ì¢… ìƒíƒœì˜ ë³´í—˜ë£Œ ì°¨ì´ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.
                        - ì„ ì²œì /ê¸°ì¡´ ì§ˆí™˜: ë³´í—˜ì‚¬ë³„ë¡œ ì œì™¸(ë¹„ê¸‰ì—¬) ì§ˆí™˜ì´ ë‹¤ë¥´ë¯€ë¡œ,
                                            êµ¬ì²´ì ì¸ ì§ˆí™˜ëª…(ì˜ˆ: ì§„í–‰ì„±ë§ë§‰ìœ„ì¶•ì¦ PRA, ê³ ê´€ì ˆì´í˜•ì„±ì¦ ë“±)ì— ëŒ€í•´
                                            ì–´ëŠ ë³´í—˜ì‚¬ê°€ ë³´ì¥í•˜ê³  ì–´ë””ëŠ” ì œì™¸í•˜ëŠ”ì§€ ëª…í™•íˆ í•˜ì„¸ìš”.
                        - í’ˆì¢…: ëŒ€í˜•ê²¬/ì†Œí˜•ê²¬, íŠ¹ì • ìœ„í—˜ í’ˆì¢…ìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ”ì§€ ì—¬ë¶€ì— ë”°ë¼
                                ë³´í—˜ë£Œ í• ì¦/í• ì¸ì´ ì°¨ì´ë‚˜ë¯€ë¡œ ì–¸ê¸‰í•˜ì„¸ìš”.

                        4. ë³´ì¥ ë²”ìœ„ ë¹„êµ ì•ˆë‚´
                        - ê°™ì€ ìƒí™©ì— ëŒ€í•´ ì—¬ëŸ¬ ë³´í—˜ì‚¬ì˜ ë³´ì¥ ë²”ìœ„ê°€ ë‹¤ë¥´ë©´:
                            â€¢ ë³´ì¥ ë²”ìœ„(ì–´ë””ê¹Œì§€ ë³´ì¥í•˜ëŠ”ê°€)
                            â€¢ ë³´ì¥ í•œë„(ìµœëŒ€ ì–¼ë§ˆê¹Œì§€ì¸ê°€)
                            â€¢ ìê¸°ë¶€ë‹´ê¸ˆ(ë³¸ì¸ ë¶€ë‹´ë¥ )
                            â€¢ ë©´ì±… ê¸°ê°„(ì–¸ì œë¶€í„° ë³´ì¥í•˜ëŠ”ê°€)
                            â€¢ ë³´í—˜ë£Œ(ì›”/ë…„ ì–¼ë§ˆì¸ê°€)
                            ë¥¼ í‘œ í˜•ì‹ ë˜ëŠ” bullet pointë¡œ ì •ë ¬í•˜ì—¬ ë¹„êµí•˜ì„¸ìš”.

                        5. ë³´í—˜ ì œë„ ì„¤ëª…
                        - ê³„ì•½ ê°€ì…: í•„ìš”í•œ ì„œë¥˜, ê±´ê°•ê²€ì§„ ì—¬ë¶€, ê°€ì… ì¡°ê±´
                        - ê³„ì•½ í•´ì§€: í•´ì§€ ìˆ˜ìˆ˜ë£Œ, í™˜ê¸‰ê¸ˆ, í•´ì§€ ì‹œ ìœ ì˜ì‚¬í•­
                        - ì²­êµ¬ ì ˆì°¨: ì–¸ì œ ì²­êµ¬í•˜ê³ , ì–´ë–¤ ì„œë¥˜ê°€ í•„ìš”í•œì§€
                        - ë©´ì±…/ì œì™¸ ì¡°í•­: ì™œ ë³´ì¥ë˜ì§€ ì•ŠëŠ”ì§€, ì–´ë–¤ ì¡°ê±´ì´ ìˆëŠ”ì§€
                        ë¥¼ ëª…í™•í•˜ê³  ë‹¨ìˆœí•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.

                        6. ë³´í—˜ìƒí’ˆ ì „ìˆ˜ì¡°ì‚¬
                        - ì§ˆë¬¸ìì˜ ì§ˆë¬¸ê³¼ ë¶€í•©í•˜ëŠ” ëª¨ë“  ë³´í—˜ì‚¬ì˜ ë³´í—˜ ìƒí’ˆ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ì—¬, ì •í™•íˆ ì‘ë‹µí•˜ì„¸ìš”.
                        - ë™ì¼í•œ ë³´í—˜ì‚¬ë¼ë„, ë³´í—˜ ìƒí’ˆ ë³„ë¡œ ì•½ê´€ ë‚´ìš© ë° ë³´ì¥ë²”ìœ„ê°€ ë‹¤ë¥´ê¸° ë•Œë¬¸ì—, ë°˜ë“œì‹œ ë³´í—˜ìƒí’ˆ ë°ì´í„° ëª¨ë‘ë¥¼ í™•ì¸í•˜ê³  ì‘ë‹µí•˜ì„¸ìš”.

                        ---

                        [ê¸ˆì§€ ì‚¬í•­]

                        1. ê°œ/ë¬˜ êµ¬ë¶„ ì—†ì´ "ë°˜ë ¤ë™ë¬¼ì´ë¼ê³ ë§Œ ë‹µí•˜ê¸°" - ë°˜ë“œì‹œ êµ¬ë¶„í•˜ì„¸ìš”.
                        2. ë³´í—˜ì‚¬ëª… ì—†ì´ "ê·¸ ìƒí’ˆì—ì„œëŠ”..." ê°™ì´ ëª¨í˜¸í•˜ê²Œ ë‹µí•˜ê¸° - ì •í™•í•œ ë³´í—˜ì‚¬ëª…ì„ ëª…ì‹œí•˜ì„¸ìš”.
                        3. ì•½ê´€ì— ì—†ëŠ” ë‚´ìš© ì¶”ì¸¡ ë˜ëŠ” ìƒì„± - ì•½ê´€ ì›ë¬¸ì— ì—†ìœ¼ë©´ "í•´ë‹¹ ì•½ê´€ì— ê¸°ì¬ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤"ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.
                        4. ìˆ˜ì¹˜ê°€ ë¹ˆì¹¸ì¸ë°ë„ ì„ì˜ì˜ ìˆ«ì ë§Œë“¤ê¸° - "í•´ë‹¹ ìƒí’ˆì˜ ì•½ê´€ì— ëª…ì‹œëœ ì¼ìˆ˜ëŠ” êµ¬ì²´ì ìœ¼ë¡œ [X]ì¼ì…ë‹ˆë‹¤"
                                                                ë˜ëŠ” "ì•½ê´€ ì›ë¬¸ì´ ë¯¸ì •ì¸ ìƒíƒœì…ë‹ˆë‹¤"ë¼ê³  ì •í™•íˆ í‘œê¸°í•˜ì„¸ìš”.
                        5. í•œ ë³´í—˜ì‚¬ë§Œ ê°•ì¡°í•˜ê±°ë‚˜ í¸í–¥ëœ ì¶”ì²œ - ê°ê´€ì  ë¹„êµë¥¼ ê¸°ë³¸ìœ¼ë¡œ í•˜ë˜,
                                                            "ë‹¹ì‹ ì˜ ë°˜ë ¤ë™ë¬¼ì´ [íŠ¹ì„±]ì´ë¼ë©´ [ë³´í—˜ì‚¬]ê°€ ë” ìœ ë¦¬í•©ë‹ˆë‹¤"
                                                            ê°™ì€ ì¡°ê±´ë¶€ ì¶”ì²œì€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

                        ---

                        [í†¤ê³¼ íƒœë„]

                        - ì „ë¬¸ì ì´ë©´ì„œë„ ì¹œê·¼í•˜ê²Œ: "ì „ë¬¸ê°€ ê°™ìœ¼ë©´ì„œë„ ì‰½ê²Œ ì´í•´í•˜ë„ë¡"
                        - ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆê²Œ: "ì•½ê´€ ê·¼ê±°ë¥¼ ëª…ì‹œí•˜ê³ , í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”"
                        - ì‚¬ìš©ì ì¤‘ì‹¬: "ë‹¹ì‹ ì˜ ë°˜ë ¤ë™ë¬¼ì´ [íŠ¹ì„±]ì¼ ë•Œ ì–´ë–¤ ì„ íƒì´ ìµœì ì¸ê°€"ë¥¼ ìƒê°í•˜ë©° ë‹µí•˜ì„¸ìš”.

                """

        return base_prompt

    @staticmethod
    def get_user_prompt(question: str, docs: List[Dict], keywords: Dict) -> str:
        context_items = []
        for i, doc in enumerate(docs, 1):
            company = doc.get('company_name') or 'ë¯¸ì •'
            product = doc.get('product_name') or 'ë¯¸ì •'
            title = doc.get('title') or ''
            clause_type = doc.get('clause_type') or ''
            coverage_limit = doc.get('coverage_limit') or 'ë¯¸ì •'
            coverage_ratio = doc.get('coverage_ratio') or 'ë¯¸ì •'
            waiting_period = doc.get('waiting_period') or 'ë¯¸ì •'
            text = (doc.get('text') or '')[:1000]
            combined_score = doc.get('combined_score', 0)

            context_items.append(f"""[ë¬¸ì„œ{i}] {company} - {product} (ì ìˆ˜: {combined_score:.2f})
ì œëª©: {title}
ìœ í˜•: {clause_type}
ë³´ì¥í•œë„: {coverage_limit}
ë³´ì¥ë¹„ìœ¨: {coverage_ratio}
ë©´ì±…ê¸°ê°„: {waiting_period}
ë‚´ìš©: {text}
---""")

        context_str = "\n".join(context_items)

        return f"""ê²€ìƒ‰ëœ ë‹¤ìŒ í«ë³´í—˜ ì•½ê´€ì„ ë³´ê³  ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

        [ê²€ìƒ‰ëœ ì•½ê´€ë“¤]
        {context_str}

        [ì‚¬ìš©ì ì§ˆë¬¸]
        {question}

        [ë‹µë³€ ì§€ì¹¨]
        1. ìœ„ ì•½ê´€ë“¤ì„ ê·¼ê±°ë¡œë§Œ ë‹µí•˜ì„¸ìš”.
        2. ë³¸ë¬¸ì—ì„œ [ë¬¸ì„œN] í† í°ì€ ì œê±°í•˜ê³  ìì—°ì–´ë¡œ í‘œí˜„í•˜ì„¸ìš”.
        3. ë³´ì¥í•œë„, ë©´ì±…ê¸°ê°„ ë“± êµ¬ì²´ì  ìˆ˜ì¹˜ëŠ” ì•½ê´€ì— ê¸°ì¬ëœ ë³´ì¥ê¸ˆì•¡ ìˆ˜ì¹˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

        [ë‹µë³€ ì˜ˆì‹œ]

        ì‚¬ìš©ì: "ìš°ë¦¬ ê°•ì•„ì§€ê°€ ìŠ¬ê´€ì ˆ íƒˆêµ¬ ì§„ë‹¨ì„ ë°›ì•˜ëŠ”ë°, í«ë³´í—˜ ê°€ì…ì´ ê°€ëŠ¥í•œê°€ìš”?"

        ì˜ˆìƒ ë‹µë³€ êµ¬ì¡°:
        1) í™•ì¸: "ê°•ì•„ì§€ì˜ ë‚˜ì´ì™€ ì²´ì¤‘, ê·¸ë¦¬ê³  ì§€ê¸ˆ ì•½ë¬¼ ì¹˜ë£Œ ì¤‘ì¸ì§€ ìˆ˜ìˆ  ì˜ˆì •ì¸ì§€ ì•Œë ¤ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?"
        2) í•µì‹¬: "ìŠ¬ê´€ì ˆ íƒˆêµ¬ëŠ” 6ê°œ ë³´í—˜ì‚¬ ëª¨ë‘ì—ì„œ ì§ˆë³‘ ë³´ì¥ ëŒ€ìƒì´ì§€ë§Œ,
                ê¸°ì¡´ ì§ˆí™˜ìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ”ì§€ ì—¬ë¶€ëŠ” ì§„ë‹¨ ì‹œì ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤."
        3) ìƒì„¸:
        - KBì†í•´ë³´í—˜ í«ë³´í—˜: "ì§„ë‹¨ ì „ ê°€ì… ì‹œ ë³´ì¥, ì§„ë‹¨ í›„ ê°€ì… ì‹œ ì œì™¸"
        - ì‚¼ì„±í™”ì¬ ì• ë‹ˆí«: "1ë…„ ë©´ì±… ê¸°ê°„ ì´í›„ë¶€í„° ë³´ì¥ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        í˜„ëŒ€í•´ìƒ í«í”ŒëŸ¬ìŠ¤: "ìˆ˜ìˆ ì€ ìµœëŒ€ 000(ìˆ«ì)ë§Œì› ë³´ì¥ ê°€ëŠ¥í•˜ë©°, ì…ì› ë° ì§„ë£Œë¹„ëŠ” ìµœëŒ€ 00(ìˆ«ì)ë§Œì› ë³´ì¥ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        4) ë¹„êµ: [í‘œ í˜•ì‹ìœ¼ë¡œ ê° ìƒí’ˆì˜ ì¡°ê±´, ë³´ì¥ í•œë„ê¸ˆì•¡, ë³´ì¥ ë²”ìœ„ ë“±ì„ ë‹µë³€ ë§¥ë½ì— ë§ê²Œ ì •ë ¬]
        5) ë§ˆë¬´ë¦¬: "ë” ìì„¸íˆ ì•Œê³  ì‹¶ì€ ë¶€ë¶„ì´ ìˆìœ¼ì‹œë©´, êµ¬ì²´ì ì¸ ì•½ê´€ì„ ì•ˆë‚´í•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."

"""


# ==========================================
# ë©”ì¸ ë´‡ (ìµœì¢… ê°œì„ íŒ)
# ==========================================
class ImprovedPetInsuranceBot:
    def __init__(self):
        self.db = DatabaseConnector()
        self.reranker = ImprovedReranker()
        self.keyword_extractor = KeywordExtractor()
        self.prompt_generator = PromptGenerator()

    def ask(self, question: str, filters: Dict = None) -> Dict:
        """ê°œì„ ëœ ì§ˆë¬¸ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""

        print(f"\nğŸ” ì§ˆë¬¸ ë¶„ì„ ì¤‘...")

        # 1. í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self.keyword_extractor.extract(question)
        print(f"   âœ“ ê°ì§€ëœ ë™ë¬¼: {keywords['animal']}")
        print(f"   âœ“ ê°ì§€ëœ ì£¼ì œ: {keywords['topics']}")

        if not filters:
            filters = {}

        # 2. ë²¡í„° ì„ë² ë”© + ê²€ìƒ‰
        q_vec = simple_embed([question])
        initial_docs = self.db.hybrid_search(q_vec, filters, limit=20)

        if not initial_docs:
            return {
                "question": question,
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì•½ê´€ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "docs": [],
                "keywords": keywords
            }

        print(f"âœ… {len(initial_docs)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨")

        # 3ï¸âƒ£ [ê°œì„ ] Reranking (ë³´í—˜ì‚¬ ë‹¤ì–‘í™”)
        print(f"ğŸ”„ Reranking ì¤‘... (ë³´í—˜ì‚¬ ë‹¤ì–‘í™” ì ìš©)")
        top_docs = self.reranker.rerank(
            question,
            initial_docs,
            top_k=6,              # âœ… 6ê°œë¡œ í™•ëŒ€
            max_per_company=2     # âœ… ë³´í—˜ì‚¬ë‹¹ ìµœëŒ€ 2ê°œ
        )
        print(f"âœ… ìµœì¢… ì„ íƒ: {len(top_docs)}ê°œ ë¬¸ì„œ (ë³´í—˜ì‚¬ ë‹¤ì–‘í™”)")

        for i, doc in enumerate(top_docs, 1):
            print(f"   [{i}] {doc['company_name']} - {doc['product_name']} (ì ìˆ˜: {doc['combined_score']:.3f})")

        # 4. í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt = self.prompt_generator.get_system_prompt(keywords)
        user_prompt = self.prompt_generator.get_user_prompt(question, top_docs, keywords)

        # 5. LLM í˜¸ì¶œ
        print(f"ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...")
        answer = call_llm_api_v2(system_prompt, user_prompt, temperature=0.2)
        answer = clean_answer(answer)

        return {
            "question": question,
            "answer": answer,
            "docs": top_docs,
            "keywords": keywords,
            "debug": {
                "initial_docs_count": len(initial_docs),
                "final_docs_count": len(top_docs),
                "topics": keywords['topics'],
                "animal": keywords['animal']
            }
        }


# ==========================================
# ì‹¤í–‰
# ==========================================
if __name__ == "__main__":
    bot = ImprovedPetInsuranceBot()
    print("âœ… í«ë³´í—˜ ì±—ë´‡ ì‹œì‘ (ë³´í—˜ì‚¬ ë‹¤ì–‘í™” ì ìš©)\n")
    print("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit' ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")

    while True:
        question = input("Q: ").strip()
        if not question:
            continue
        if question.lower() in ["quit", "exit", "ì¢…ë£Œ", "ë"]:
            print("ğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        print("=" * 90)
        print(f"Q: {question}")
        print("=" * 90)

        result = bot.ask(question)

        print(f"\nğŸ“ ë‹µë³€:\n{result['answer']}\n")
        print("=" * 90 + "\n")

